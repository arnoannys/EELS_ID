{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "from data_parameters import data_param\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by getting the SI preprocessed (normalized, zero padded, alligned, ...) and save it to a TFRecord so that we dont have to repeat the operations every time. We use a SI from Chen, B., Gauquelin, N., Strkalj, N. et al. Signatures of enhanced out-of-plane polarization in asymmetric BaTiO3 superlattices integrated on silicon. Nat Commun 13, 265 (2022). https://doi.org/10.1038/s41467-021-27898-x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run IO_help/SI_to_TFRecord.py --name=SI_Chen --extension=dm3 --offset=20\n",
    "filename = 'SI_data/SI_Chen'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a NN, here pick the ensemble since it is the most robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f'trained element identification models/2ViT_3UNet_ensemble',custom_objects={\"custom_loss\": utils.custom_loss}) \n",
    "threshold = 0.75"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose some selection criterion to surpress likely false positives, for example only consider elements that occur in 1% of the spectra\n",
    ". You can just put this to zero to see all positive identifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentration_threshold = 0.01"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_sys = data_param['per_sys']\n",
    "N_elem = len(per_sys)\n",
    "spectrum_length = data_param['spectrum_length']\n",
    "batch_size = 4072\n",
    "def parse_tfr_element(element):\n",
    "    length = spectrum_length\n",
    "    #use the same structure as in writing; \n",
    "    data = {\n",
    "        'raw_spec' : tf.io.FixedLenFeature([], tf.string),\n",
    "        'idx_0': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'idx_1': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'sum': tf.io.FixedLenFeature([], tf.float32),\n",
    "           }\n",
    "\n",
    "      \n",
    "    content = tf.io.parse_single_example(element, data)\n",
    "    \n",
    "    raw_spec = content['raw_spec']\n",
    "    idx_0 = content['idx_0']\n",
    "    idx_1 = content['idx_1']\n",
    "    I = content['sum']\n",
    "  \n",
    "    feature = tf.io.parse_tensor(raw_spec, out_type=tf.float64)\n",
    "    feature = tf.reshape(feature, shape=[length])\n",
    "    return (feature,idx_0,idx_1,I)\n",
    "\n",
    "def get_dataset(filename):\n",
    "    #create the dataset\n",
    "    dataset = tf.data.TFRecordDataset(filename)\n",
    "\n",
    "    #pass every single feature through our mapping function\n",
    "    dataset = dataset.map(\n",
    "        parse_tfr_element\n",
    "    )\n",
    "      \n",
    "    return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a series of maps (one for each element) with binary predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{filename}_metadata.json') as f:\n",
    "    metadata = json.load(f)\n",
    "idx0_range = metadata['idx_0_range']\n",
    "idx1_range = metadata['idx_1_range']\n",
    "idx0_step = metadata['idx_0_step']\n",
    "idx1_step = metadata['idx_1_step']\n",
    "units = metadata['idx_0_units']\n",
    "\n",
    "Im = np.zeros(shape=(idx0_range,idx1_range))\n",
    "for spec, idx0,idx1,i in get_dataset(f'{filename}.tfrecords').take(-1):\n",
    "    idx0,idx1 = idx0.numpy(),idx1.numpy()\n",
    "    Im[idx0,idx1] = i.numpy()\n",
    "\n",
    "\n",
    "coord = get_dataset(f'{filename}.tfrecords').batch(batch_size,drop_remainder=False)\n",
    "map = np.zeros(shape=(idx0_range,idx1_range,N_elem), dtype=np.float64)\n",
    "\n",
    "for spec,IDX0,IDX1,i in coord.take(-1):\n",
    "    pred = model.predict(spec,verbose=0, workers=10,use_multiprocessing=True)\n",
    "    IDX0 = IDX0.numpy()\n",
    "    IDX1 = IDX1.numpy()\n",
    "    for N in range(int(tf.shape(spec)[0])):\n",
    "        idx0,idx1 = IDX0[N],IDX1[N]\n",
    "        idx_found = np.where(pred[N] > threshold)\n",
    "        map[idx0,idx1,idx_found] = 1\n",
    "\n",
    "\n",
    "c = []\n",
    "for i in range(N_elem):\n",
    "    if np.sum(map[:,:,i])/(idx0_range*idx1_range) > concentration_threshold:\n",
    "        c.append(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the predictions. Be sure to check the pdf result because the pop-up image might not properly display some details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements_per_row = 5\n",
    "s = int(np.ceil(len(c)/elements_per_row))\n",
    "\n",
    "fig, ax = plt.subplots(s,elements_per_row,figsize=(elements_per_row,s*5))\n",
    "\n",
    "n = 0\n",
    "if s==1:\n",
    "    for j in range(elements_per_row):\n",
    "        if n < len(c):\n",
    "            k = c[n]\n",
    "            heatmap = map[:,:,k]\n",
    "            heatmap = np.where(heatmap == 0., np.nan, heatmap)\n",
    "            ax[j].imshow(Im.T/np.max(Im),cmap = \"gray\")\n",
    "            im = ax[j].imshow(heatmap.T,cmap = 'Reds',alpha=0.7)\n",
    "            cb = plt.colorbar(im)\n",
    "            ax[j].set_title(per_sys[k])\n",
    "            n +=1\n",
    "            cb.remove() \n",
    "        ax[j].axis('off')\n",
    "else:\n",
    "    for i in range(s):\n",
    "        for j in range(elements_per_row):\n",
    "            if n < len(c):\n",
    "                k = c[n]\n",
    "                heatmap = map[:,:,k]\n",
    "                heatmap = np.where(heatmap == 0., np.nan, heatmap)\n",
    "                ax[i,j].imshow(Im.T/np.max(Im),cmap = \"gray\")\n",
    "                im = ax[i,j].imshow(heatmap.T,cmap = 'Reds',alpha=0.7)\n",
    "                cb = plt.colorbar(im)\n",
    "                ax[i,j].set_title(per_sys[k])\n",
    "                n +=1\n",
    "                cb.remove() \n",
    "            ax[i,j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('mapping_result.pdf',dpi=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a471a25ffcd2d79bb82c85243e7b644082b228fb0aecb1b9bdd7ff40df403d4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
