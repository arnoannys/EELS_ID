{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22296,"status":"ok","timestamp":1663049397402,"user":{"displayName":"Arno Annys","userId":"02992148994794771843"},"user_tz":-120},"id":"MEjqdKnQOptj","outputId":"3e73e817-d98e-40ea-ad80-3aeafef04c15"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","import utils\n","from utils import Visuals\n","import evaluators\n","import tensorflow_addons as tfa\n","from data_parameters import data_param\n","\n","print(tf.config.experimental.get_visible_devices())\n","\n","per_sys = data_param['per_sys']\n","N_elem = len(per_sys)\n","spectrum_length = data_param['spectrum_length']\n","max_buffer = data_param['max_buffer']\n","batch_size = 32\n","\n","val_dataset = utils.get_dataset(tf.data.TFRecordDataset.list_files('Core-loss EELS TFRecord/validationset/VALIDATION*.tfrecords', shuffle=True))\n","val_dataset = val_dataset.batch(batch_size,drop_remainder=True).prefetch(tf.data.AUTOTUNE) \n","\n","test_dataset = utils.get_dataset(tf.data.TFRecordDataset.list_files('Core-loss EELS TFRecord/testset/TEST*.tfrecords', shuffle=True))\n","test_dataset = test_dataset.shuffle(max_buffer,reshuffle_each_iteration=False).batch(batch_size,drop_remainder=True).prefetch(tf.data.AUTOTUNE)  \n","\n","confmat_dataset = utils.get_dataset(tf.data.TFRecordDataset.list_files(\"Core-loss EELS TFRecord/single_element_spec/*.tfrecords\", shuffle=True))\n","confmat_dataset = confmat_dataset.batch(8000).prefetch(tf.data.AUTOTUNE) #confusion matrix function only takes a single batch at the moment"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## load a model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = tf.keras.models.load_model('trained element identification models/2ViT_3UNet_ensemble', custom_objects={'custom_loss' : utils.custom_loss}) "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## set threshold"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["threshold = 0.35 # this is the threshold that leads to equal precision and recall for the 2xVit+3xUNet ensemble on simulated data.\n","#note that the simulated data has a lot of edges with boundlessly small jump ratios (and SNR) that bring this threshold down a lot. The optimal threshold \n","# for the 2xVit+3xUNet ensemble on experimental data is 0.75 , for the ViT it is 0.80 and for the UNet is is 0.95"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## or determine the best threshold from validation data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dset = val_dataset\n","\n","metrics = [tfa.metrics.F1Score(N_elem, 'weighted', th, name = f'f1_{th}') for th in np.arange(0.05,1,0.05)]\n","model.compile(\n","            optimizer=tf.optimizers.Adam(learning_rate=0.001),  \n","                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),   \n","                metrics= metrics)\n","fscores = model.evaluate(dset)[1::]\n","\n","metrics = [tf.metrics.Precision(th, name = f'prec_{th}') for th in np.arange(0.05,1,0.05)]\n","model.compile(\n","            optimizer=tf.optimizers.Adam(learning_rate=0.001),  \n","                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),   \n","                metrics= metrics)\n","precisions = model.evaluate(dset)[1::]\n","\n","metrics = [tf.metrics.Recall(th, name = f'rec_{th}') for th in np.arange(0.05,1,0.05)]\n","model.compile(\n","            optimizer=tf.optimizers.Adam(learning_rate=0.001),  \n","                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),   \n","                metrics= metrics)\n","recalls = model.evaluate(dset)[1::]\n","\n","\n","plt.figure(figsize=(12,5))\n","plt.scatter(np.arange(0.05,1,0.05),fscores, marker='o',c = 'k',label = r'F$_1$')\n","plt.scatter(np.arange(0.05,1,0.05),precisions,marker='s',c= 'r' , label = 'precision')\n","plt.scatter(np.arange(0.05,1,0.05),recalls,marker = 'v', c = 'b', label = 'recall')\n","plt.xticks(np.arange(0.05,1,0.05))\n","plt.legend()\n","plt.xlabel('Threshold')\n","plt.ylabel('Value')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## get metrics for testset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#selected part of test dataset (full one takes quite a while)\n","evaluators.numeric_metrics(model=model,dataset=test_dataset.take(500),threshold=threshold,drop_carbon=False)\n","\n","EMR = evaluators.match_rate(model=model,threshold=threshold,drop_carbon=False)\n","print(EMR.calculate(test_dataset.take(500)).numpy())"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## get confusion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["CMM = evaluators.confusionmatrix(class_names = per_sys,model = model,dataset = confmat_dataset)\n","CMM.plot_confusion_matrix()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## visualize predictions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["visuals = Visuals()\n","visuals.visual_prediction(model=model,dataset=test_dataset.take(1),start=0,end=6,threshold=threshold)\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOEMTzpu2N8nroYP0M6Vv8G","collapsed_sections":[],"mount_file_id":"1W1nalBQqj_wue7p3h0-7rvBusNGOi-w6","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"py39","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"},"vscode":{"interpreter":{"hash":"a471a25ffcd2d79bb82c85243e7b644082b228fb0aecb1b9bdd7ff40df403d4c"}}},"nbformat":4,"nbformat_minor":0}
