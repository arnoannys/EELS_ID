{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22296,"status":"ok","timestamp":1663049397402,"user":{"displayName":"Arno Annys","userId":"02992148994794771843"},"user_tz":-120},"id":"MEjqdKnQOptj","outputId":"3e73e817-d98e-40ea-ad80-3aeafef04c15"},"outputs":[],"source":["import tensorflow as tf\n","import utils\n","import tensorflow_addons as tfa\n","from data_parameters import data_param\n","import models.identification_models as models\n","\n","print(tf.config.experimental.get_visible_devices())\n","\n","per_sys = data_param['per_sys']\n","N_elem = len(per_sys)\n","spectrum_length = data_param['spectrum_length']\n","max_buffer = data_param['max_buffer'] # loads all data in to RAM to shuffle; requires a lot of RAM! (more than data which is about 20G; could pre shuffle data and then use smaller buffer)\n","batch_size = 32\n","\n","\n","train_dataset = utils.get_dataset(tf.data.TFRecordDataset.list_files('Core-loss EELS TFRecord/trainingset/TRAIN*.tfrecords', shuffle=True))\n","train_dataset = train_dataset.shuffle(buffer_size= max_buffer , reshuffle_each_iteration=True).batch(batch_size).prefetch(tf.data.AUTOTUNE) \n","\n","val_dataset = utils.get_dataset(tf.data.TFRecordDataset.list_files('Core-loss EELS TFRecord/validationset/VALIDATION*.tfrecords', shuffle=True))\n","val_dataset = val_dataset.shuffle(buffer_size= max_buffer , reshuffle_each_iteration=True).batch(batch_size).prefetch(tf.data.AUTOTUNE)  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OF8cASmZOnLb"},"outputs":[],"source":["!rm -rf 'logs/fit'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_type = \"UNet_1x1conv\"\n","\n","#recommended\n","if model_type == \"UNet_1x1conv\":\n","    model = models.UNet(spectrum_length = spectrum_length, N_elem = N_elem,reduction_method = \"1x1conv\")\n","    LR = 0.001\n","elif model_type == \"ViT_1x1conv\":\n","    model = models.ViT(spectrum_length = spectrum_length, N_elem = N_elem,reduction_method = \"1x1conv\")\n","    LR = 0.001\n","    \n","#less recommended\n","'''\n","elif model_type == \"MLP\":\n","    model = models.MLP(spectrum_length = spectrum_length, N_elem = N_elem)\n","elif model_type == \"CNN\":\n","    model = models.CNN(spectrum_length = spectrum_length, N_elem = N_elem)\n","elif model_type == \"ResNet_GAP\":\n","    model = models.ResNet(spectrum_length = spectrum_length, N_elem = N_elem,reduction_method = \"GAP\")\n","elif model_type == \"ResNet_1x1conv\":\n","    model = models.ResNet(spectrum_length = spectrum_length, N_elem = N_elem,reduction_method = \"1x1conv\")\n","elif model_type == \"ResNet_flatten\":\n","    model = models.ResNet(spectrum_length = spectrum_length, N_elem = N_elem,reduction_method = \"flatten\")\n","elif model_type == \"UNet_GAP\":\n","    model = models.UNet(spectrum_length = spectrum_length, N_elem = N_elem,reduction_method = \"GAP\")\n","elif model_type == \"CCT_1x1conv\":\n","    model = models.CCT(spectrum_length=spectrum_length,N_elem=N_elem,reduction_method = \"1x1conv\")\n","elif model_type == \"CCT_seq_pool\":\n","    model = models.CCT(spectrum_length=spectrum_length,N_elem=N_elem,reduction_method = \"seq_pool\")\n","elif model_type == \"ViT_GAP\":\n","    model = models.ViT(spectrum_length = spectrum_length, N_elem = N_elem,reduction_method = \"GAP\")\n","elif model_type == \"ViT_flatten\":\n","    model = models.ViT(spectrum_length = spectrum_length, N_elem = N_elem,reduction_method = \"flatten\")\n","elif model_type == \"ViT_token\":\n","    model = models.ViT(spectrum_length = spectrum_length, N_elem = N_elem,reduction_method = \"token\")\n","'''\n","\n","\n","log_dir = f\"logs/fit/{model_type}\"\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR),   \n","            loss=utils.custom_loss,\n","            metrics= [tfa.metrics.F1Score(N_elem, 'weighted', 0.8, name = 'f1')],\n","            ) \n","model.summary()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### TRAIN A SINGLE MODEL"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1278939,"status":"ok","timestamp":1663052353114,"user":{"displayName":"Arno Annys","userId":"02992148994794771843"},"user_tz":-120},"id":"DPnwuCwxriuH"},"outputs":[],"source":["reduce_LR = tf.keras.callbacks.ReduceLROnPlateau(monitor='f1',factor=0.5,patience=3,mode='max',min_delta=0.025)\n","\n","class LR_limit_stop(tf.keras.callbacks.Callback):\n","\tdef on_epoch_end(self, epoch, logs={}):\n","\t\tif(logs.get('lr') < 5e-6):\n","\t\t\tself.model.stop_training = True\n","lr_stop = LR_limit_stop()\n","\n","model.fit(train_dataset.repeat(2),\n","\t        validation_data= val_dataset, \n","            epochs=35, \n","            verbose= 1, \n","            callbacks=[tensorboard_callback,reduce_LR, lr_stop],\n","            workers = 8,\n","            use_multiprocessing=True,\n","            steps_per_epoch=1000,\n","            )"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### SAVE A TRAINED MODEL  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.save(f'newly_trained_models/trained_{model_type}')"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOEMTzpu2N8nroYP0M6Vv8G","collapsed_sections":[],"mount_file_id":"1W1nalBQqj_wue7p3h0-7rvBusNGOi-w6","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"py39","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"},"vscode":{"interpreter":{"hash":"a471a25ffcd2d79bb82c85243e7b644082b228fb0aecb1b9bdd7ff40df403d4c"}}},"nbformat":4,"nbformat_minor":0}
